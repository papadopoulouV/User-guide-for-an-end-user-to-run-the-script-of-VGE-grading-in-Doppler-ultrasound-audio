{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd65e15a",
   "metadata": {},
   "source": [
    "## <span style='color:red'> GitHub Repository for Doppler VGE Detection Inference </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e756637",
   "metadata": {},
   "source": [
    "## <span style='color:green'> Reading audio file(s) </span>\n",
    "\n",
    "- ###  It can be a single audio file or a batch of files in a folder (different audio formats)\n",
    "- ### Quality check \n",
    "- ### Sample rate check (resampling to 8 kHz if needed)\n",
    "- ### Length check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ffc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Folder selection for the data to process\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "import glob, os\n",
    "import soundfile as sf\n",
    "import scipy.signal as sps\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "win= Tk()\n",
    "win.geometry(\"250x100\")\n",
    "win.title(\"Folder Selection Window\")\n",
    "def select_file():\n",
    "    global path\n",
    "    path = filedialog.askdirectory(title=\"Select a Folder\")\n",
    "    \n",
    "Label(win, text=\"Click Select a Folder\", font=('Aerial 10 bold')).pack(pady=20)\n",
    "\n",
    "button = ttk.Button(win, text=\"Select a Folder\", command= select_file)\n",
    "close = ttk.Button(win, text=\"Close\", command= win.destroy)\n",
    "\n",
    "button.pack(ipadx=20, pady=5, side = 'left')\n",
    "close.pack(ipadx=20, pady=5, side = 'right')\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Grabbing the audio files within the folder\n",
    "\n",
    "# Supporting single extension of audio files\n",
    "\n",
    "# filelist = []\n",
    "# os.chdir(path)\n",
    "# for file in glob.glob(\"*.flac\"):\n",
    "#     global filelist\n",
    "#     filelist.append(os.path.join(path, file))\n",
    "\n",
    "# ************************************************* #\n",
    "\n",
    "# Supporting multiple extensions of audio files\n",
    "\n",
    "filelist = []\n",
    "os.chdir(path)\n",
    "extensions = (\"*.wav\",\"*.flac\", \".mp3\")\n",
    "for extension in extensions:\n",
    "    global filelist\n",
    "    filelist.extend(glob.glob(path+\"/\"+extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) Sample rate check\n",
    "new_rate = 8000\n",
    "arrayData = {}\n",
    "for file in filelist:\n",
    "    data,  sampling_rate = sf.read(file)\n",
    "    ## Only un-comment two lines below for multi-channel audio data\n",
    "#     if data.shape[1] == 2:\n",
    "#         data = data[:,1]\n",
    "    if sampling_rate != new_rate:\n",
    "        number_of_samples = round(len(data) * float(new_rate) / sampling_rate)\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "        arrayData[os.path.split(file)[1]] = data\n",
    "        print('******** The audio file {} was resampled! **********'.format(os.path.split(file)[1]))\n",
    "    else:\n",
    "        arrayData[os.path.split(file)[1]] = data\n",
    "        print('******** The audio file {} was not resampled! **********'.format(os.path.split(file)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2494f9",
   "metadata": {},
   "source": [
    "## <span style='color:green'> Check if subclavian or precordial is selected </span>\n",
    "- ### Selection of proper model to test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f425a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To use the pre-trained models, the following steps should be performed:\n",
    "###### 1) Create a folder in the selected folder above and name it \"Models\" (Make sure \"M\" is UPPERCASE)\n",
    "###### 2) Download and place the models in GitHub, i.e., \"RAW_PRECORDIAL.h5\" and \"RAW_PRECORDIAL.h5\" within the \"Models\" folder\n",
    "###### 3) Run the script below.\n",
    "global modelType\n",
    "modelType = os.path.split(path)[1]\n",
    "mainFolder = os.path.split(path)[0]\n",
    "if modelType == 'Subclvian':\n",
    "    modelPath = os.path.join(os.path.join(mainFolder, 'Models'), 'RAW_SUBCLAVIAN.h5')\n",
    "    model_to_apply = keras.models.load_model(modelPath)\n",
    "else:\n",
    "    modelPath = os.path.join(os.path.join(mainFolder, 'Models'), 'RAW_PRECORDIAL.h5')\n",
    "    model_to_apply = keras.models.load_model(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bab7a9",
   "metadata": {},
   "source": [
    "## <span style='color:green'> Different algorithms to check on the 10-seconds long segments </span>\n",
    "- ### Majority voting for non-overlap segments \n",
    "- ### Majority voting with a rolling average (50% overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Majority voting for non-overlap segments\n",
    "\n",
    "L =  len(arrayData) # files to test\n",
    "timeSlice = 10 # seconds\n",
    "overlapSize = 5 # seconds\n",
    "rawDoppler = []\n",
    "audioAnnotator = []\n",
    "FinScores = open(modelType + \"_NonOverlap_FinalScores.csv\",'w')\n",
    "FinScores.write('File ID,Segment,Predicted Grade\\n')\n",
    "\n",
    "for k, v in arrayData.items():\n",
    "    v = v.astype(np.float32)\n",
    "    nClips = int(len(v)/(timeSlice*new_rate))\n",
    "    if nClips == 0:\n",
    "        continue\n",
    "    for m in range(nClips):\n",
    "        rawDoppler.append(v[timeSlice*m*new_rate:timeSlice*(m+1)*new_rate])\n",
    "        audioAnnotator.append(k)\n",
    "        rawDoppler10s = np.asarray(rawDoppler)\n",
    "        y_pred = model_to_apply.predict(rawDoppler10s)\n",
    "        print('File ID: {}, Segment: {}, Predicted Grade: {}'.format(audioAnnotator, m, np.argmax(y_pred)))\n",
    "        fileID = str(audioAnnotator)\n",
    "        segmentID = str(m)\n",
    "        PredictedGrade = str(np.argmax(y_pred))\n",
    "        line = \",\".join([fileID,segmentID,PredictedGrade])\n",
    "        FinScores.write(line+\"\\n\")                \n",
    "\n",
    "        rawDoppler = []\n",
    "        audioAnnotator = []\n",
    "\n",
    "    print(\"***********End of audio file {}***********\".format(k))\n",
    "FinScores.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Majority voting with a rolling average (50% overlap)\n",
    "\n",
    "L =  len(arrayData) # files to test\n",
    "timeSlice = 10 # seconds\n",
    "overlapSize = 5 # seconds\n",
    "rawDoppler = []\n",
    "audioAnnotator = []\n",
    "FinScores1 = open(modelType + \"_Overlapping_FinalScores.csv\",'w')\n",
    "FinScores1.write('File ID,Segment,Predicted Grade\\n')\n",
    "for k, v in arrayData.items():\n",
    "    v = v.astype(np.float32)\n",
    "    nClips = int(len(v)/(overlapSize*new_rate)) - 1\n",
    "    if nClips == 0:\n",
    "        continue\n",
    "    for m in range(nClips):\n",
    "        rawDoppler.append(v[timeSlice*m*new_rate - m*new_rate*overlapSize : timeSlice*(m+1)*new_rate - m*new_rate*overlapSize])\n",
    "        audioAnnotator.append(k)\n",
    "        rawDoppler10s = np.asarray(rawDoppler)\n",
    "        y_pred = model_to_apply.predict(rawDoppler10s)\n",
    "        print('File ID: {}, Segment: {}, Predicted Grade: {}'.format(audioAnnotator, m, np.argmax(y_pred)))\n",
    "        fileID = str(audioAnnotator)\n",
    "        segmentID = str(m)\n",
    "        PredictedGrade = str(np.argmax(y_pred))\n",
    "        line = \",\".join([fileID,segmentID,PredictedGrade])\n",
    "        FinScores1.write(line+\"\\n\")                \n",
    "\n",
    "        rawDoppler = []\n",
    "        audioAnnotator = []\n",
    "\n",
    "    print(\"***********End of audio file {}***********\".format(k))\n",
    "FinScores1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452887c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
